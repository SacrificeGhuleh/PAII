// includes, cuda
#include <cstdint>
#include <climits>
#include <cuda_runtime.h>
#include <helper_cuda.h>

#include <cudaDefs.h>
#include <imageManager.h>

#include "arrayUtils.cuh"

#define BENCHMARK_NUM_REPS 100			// number of repetitions for benchmarking
#define TPB 512							// ThreadsPerBlock (1D block)
#define TPB_REDUCTION 512				// ThreadsPerBlock (1D block)

cudaError_t error = cudaSuccess;
cudaDeviceProp deviceProp = cudaDeviceProp();

using DT = uint8_t;						// Working data type

struct alignas(8) ResultType
{
	float fitness;
	uint32_t idx;
	
	ResultType& operator=(ResultType&&) = default;				//Forcing a move assignment operator to be generated by the compiler

	__host__ __device__ volatile ResultType& operator=(volatile const ResultType& other) volatile
	{
		fitness = other.fitness;
		idx = other.idx;
		return *this;
	}
};

struct Image
{
	uint32_t width = 0;
	uint32_t height = 0;
	uint32_t pitch = 0;
	DT* ptr = nullptr;
};

void prepareData(const char* imageFileName, Image& img)
{
	FIBITMAP* tmpA = ImageManager::GenericLoader(imageFileName, 0);
	img.width = FreeImage_GetWidth(tmpA);
	img.height = FreeImage_GetHeight(tmpA);
	img.pitch = FreeImage_GetPitch(tmpA);		// FREEIMAGE align row data ... You have to use pitch instead of width

	//Create a memory block using UNIFIED MEMORY to store original image. This is a redundant copy, however the data will be ready to use directly by GPU.
	uint8_t* tmpB = nullptr;
	size_t imageSize = static_cast<size_t>(img.pitch * img.height * FreeImage_GetBPP(tmpA)) >> 3; //posun, deleni osmi, BPP je v bitech, chceme byty
	checkCudaErrors(cudaMallocManaged(&tmpB, imageSize));
	checkCudaErrors(cudaMemcpy(tmpB, FreeImage_GetBits(tmpA), imageSize, cudaMemcpyHostToDevice));
	//checkHostMatrix(tmpB, img.pitch, img.height, img.width, "%d ", "Reference");

	FreeImage_Unload(tmpA);

	//Create a memory block using UNIFIED MEMORY to store DT data and convert tmpB -> img.ptr
	checkCudaErrors(cudaMallocManaged(&img.ptr, img.width * img.height * sizeof(DT)));

	dim3 block{ TPB,1,1 };
	dim3 grid{ getNumberOfParts(img.width * img.height, TPB), 1, 1 };
	arrayReshape<uint8_t, DT> <<<grid, block>> > (tmpB, img.width, img.height, img.pitch, img.width, img.height, img.width*sizeof(DT), img.ptr);
	
	//From now, we have a new pitch of the final data.
	img.pitch = img.width * sizeof(DT);
	
	//Some synchronization must be called when using UNIFIED MEMORY in async. Previous kernel was called asynchronously!!!
	cudaDeviceSynchronize();
	//checkHostMatrix(img.ptr, img.width * sizeof(DT), img.height, img.width, "%0.2f ", "Reference");
}


//Every block computes one final fitness value for a single pixel of the reference image. One corner of the query image is "virtually" attached to this pixel position. Then a single thread block
//compares the query image with the given region of the reference image. 
//In the worst case it means that one needs (ref.width * ref.height) thread blocks which could exceed the value allowed by GPU. That's why we use only (ref.width - query.width) which will pass through by
//the reference image row by row. The cons is that there will be one extra loop.
__global__ void find0(const DT* __restrict__ ref, const uint32_t rWidth, const uint32_t rHeight,
			          const DT* __restrict__ query, const uint32_t qWidth, const uint32_t qHeight, 
				      float* __restrict__ fitness)
{
	uint32_t tid = threadIdx.x;

	uint32_t rx, ry;
	const uint32_t rxOffset = gridDim.x;

	uint32_t qx, qy;
	const uint32_t qxOffset = blockDim.x;

	const DT* r = nullptr;
	const DT* q = nullptr;

	__shared__ float comp[TPB];

	ry = 0;													//All blocks start from the 0-th row.
	while (ry <= rHeight-qHeight)							//It is supposed that we want to compare the whole pattern. It means that the query image must be completely inside the reference one.
	{
		rx = blockIdx.x;
		
		while (rx <= rWidth - qWidth)						//It is supposed that we want to compare the whole pattern. It means that the query image must be completely inside the reference one.
		{
			comp[tid] = 0.0f;								//Clear the shared memory because of the outer loop where the computation start from scratch. No sync is needed because every thread access only its value.

			r = &ref[ry * rWidth + rx];						//Pointer to starting ROW position in the reference image.
			q = &query[0];									//Pointer to starting ROW position in the query image.

			qy = 0;
			while (qy < qHeight)							//The same thread block is moving over the reference and query image row by row and computes a fitness value.
			{
				qx = tid;									//Each thread has own index in the query image.
				while (qx < qWidth)					
				{
					comp[qx] += (r[qx] - q[qx]) * (r[qx] - q[qx]);		//Cummulate the value for n*tid-th column.
					qx += qxOffset;
				}

				r += rWidth;								//Move one row down in the reference image.
				q += qWidth;								//Move one row down in the query image.
				qy++;
			}

			__syncthreads();								//The parallel reduction will start here, all WARPS has to finish previous instructions.

			for (uint32_t s = (TPB >> 1); s > 32; s >>= 1)	//This can be UNROLLED when the TPB is fixed for the application
			{
				if (tid < s)
					comp[tid] += comp[tid + s];
				__syncthreads();
			}
			if (tid < 32)									//Only one warp is active here, no sync is needed.
			{
				volatile float* vComp = comp;
				vComp[tid] += vComp[tid + 32];
				vComp[tid] += vComp[tid + 16];
				vComp[tid] += vComp[tid + 8];
				vComp[tid] += vComp[tid + 4];
				vComp[tid] += vComp[tid + 2];
				vComp[tid] += vComp[tid + 1];
			}

			if (tid == 0)									//0-th thread stores the final fitness value
			{
				fitness[ry * rWidth + rx] = comp[0];
			}

			rx+= rxOffset;									//Move to another pixel that will be the starting position for the comparison.
		}

		//Move block down by 1 pixel in the reference image.
		ry++;
	}
}

//One 1D block reduction
__global__ void getBest(const float* __restrict__ data, const uint32_t length, ResultType* __restrict__ result)
{
	__shared__ ResultType sData[TPB_REDUCTION];
	
	uint32_t tid = threadIdx.x;
	const uint32_t offset = blockDim.x;
			
	sData[tid] = { FLT_MAX , 0 };								//Initial fill of the shared memory
	if (tid < length)											
	{
		sData[tid] = { data[tid], tid };
	}

	uint32_t nextId = tid + offset;
	float* ptr = (float*)&data[nextId];							//Pointer to global mem;

	while (nextId < length)										//Compare rest of data from the global memory
	{
		if (*ptr < sData[tid].fitness)
		{
			sData[tid] = { *ptr, nextId };
		}
		ptr += offset;
		nextId += offset;
	}

	__syncthreads();											//Start reduction from now

	for (uint32_t s = (TPB_REDUCTION >> 1); s > 32; s >>= 1)	//This can be UNROLLED when the TPB is fixed for the application
	{
		if (tid < s)
		{
			if (sData[tid + s].fitness < sData[tid].fitness)
			{
				sData[tid] = sData[tid + s];
			}
		}
		__syncthreads();
	}
	if (tid < 32)												//Only one warm is active here, no sync is needed.
	{
		volatile ResultType* vsData = sData;

		//WARNING!!! THIS IS A BAD CODE. THE IF CONDITION BREAKS WARPS AND SO CAN ALSO BREAK THE ORDER OF EVALUATIONS OF ELEMENTS.

		//if (vsData[tid + 32].fitness < vsData[tid].fitness) vsData[tid] = vsData[tid + 32];
		//if (vsData[tid + 16].fitness < vsData[tid].fitness) vsData[tid] = vsData[tid + 16];
		//if (vsData[tid + 8].fitness < vsData[tid].fitness) vsData[tid] = vsData[tid + 8];
		//if (vsData[tid + 4].fitness < vsData[tid].fitness) vsData[tid] = vsData[tid + 4];
		//if (vsData[tid + 2].fitness < vsData[tid].fitness) vsData[tid] = vsData[tid + 2];
		//if (vsData[tid + 1].fitness < vsData[tid].fitness) vsData[tid] = vsData[tid + 1];

		//ALL THREADS HAS TO DO THE SAME INSTRUCTIONS !!!
		vsData[tid] = (vsData[tid].fitness < vsData[tid + 32].fitness) ? vsData[tid] : vsData[tid + 32];
		vsData[tid] = (vsData[tid].fitness < vsData[tid + 16].fitness) ? vsData[tid] : vsData[tid + 16];
		vsData[tid] = (vsData[tid].fitness < vsData[tid + 8].fitness) ? vsData[tid] : vsData[tid + 8];
		vsData[tid] = (vsData[tid].fitness < vsData[tid + 4].fitness) ? vsData[tid] : vsData[tid + 4];
		vsData[tid] = (vsData[tid].fitness < vsData[tid + 2].fitness) ? vsData[tid] : vsData[tid + 2];
		vsData[tid] = (vsData[tid].fitness < vsData[tid + 1].fitness) ? vsData[tid] : vsData[tid + 1];
	}

	if (tid == 0)												//The zero thread saves the result into Global mem
	{
		*result = sData[0];
	}
}


int main(int argc, char* argv[])
{
	initializeCUDA(deviceProp);

	Image ref;
	Image query;

	FreeImage_Initialise();
	prepareData("./Data/reference.tif", ref);
	prepareData("./Data/query.tif", query);
	FreeImage_DeInitialise();

	cudaEvent_t start, stop;
	cudaEventCreate(&start);
	cudaEventCreate(&stop);

	float* fitness = nullptr;
	size_t fitnessSize = static_cast<size_t>(ref.width * ref.height *sizeof(float));
	checkCudaErrors(cudaMallocManaged(&fitness, fitnessSize));
	checkCudaErrors(cudaMemset(fitness, 0, fitnessSize));

	ResultType* result = nullptr;
	checkCudaErrors(cudaMallocManaged(&result, sizeof(ResultType)));

	checkCudaErrors(cudaEventRecord(start, 0));

	//1. Initialize fitness values. This is a C-style workaround. The fitness function search for minimum, that's why all is set to MAX. This avoids further IF-ELSE in the code!
	dim3 block{ 1024 ,1,1 };
	dim3 grid{ 256, 1, 1 };			//E.g. 256 blocks
	arrayInit<<<grid, block>>>(fitness, ref.width * ref.height, FLT_MAX);

	//2. Try to compute all possible matches.
	block = { TPB,1,1 };
	grid = { 256, 1, 1 };			//E.g. 256 blocks
	find0<<<grid, block>>>(ref.ptr, ref.width, ref.height, query.ptr, query.width, query.height, fitness);
	
	//3. Search for the best match
	block = { TPB_REDUCTION ,1,1 };
	grid = { 1, 1, 1 };
	getBest<<<grid, block>>>(fitness, ref.width * ref.height, result);

	checkCudaErrors(cudaEventRecord(stop, 0));
	checkCudaErrors(cudaEventSynchronize(stop));
	float elapsedTime;
	checkCudaErrors(cudaEventElapsedTime(&elapsedTime, start, stop));
	cudaEventDestroy(start);
	cudaEventDestroy(stop);

	//checkHostMatrix(fitness, ref.width * sizeof(float), ref.height, ref.width, "%0.2f ", "Fitness");

	printf("Best fitness value: %f\n", result->fitness);
	printf("Winner index: %u\n", result->idx);
	printf("Winner's LEFT-TOP CORNER X: %u\n", result->idx % ref.width);
	printf("Winner's LEFT-TOP CORNER Y: %u\n", ref.height - (result->idx / ref.width) - query.height);
	printf("Computation time: %f ms\n", elapsedTime);

	if (ref.ptr) cudaFree(ref.ptr);
	if (query.ptr) cudaFree(query.ptr);
	if (fitness) cudaFree(fitness);
	if (result) cudaFree(result);
}
